{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ececa80",
   "metadata": {},
   "source": [
    "#STEP 1 BW_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import *\n",
    "#import Biopython for alignment\n",
    "\n",
    "def readin_files(file):\n",
    "    data_list = []\n",
    "    with open(file) as open_file:\n",
    "        for line in open_file:\n",
    "            data_list.append(line[:-1])\n",
    "    return data_list\n",
    "#defines the reading of files\n",
    "\n",
    "assignment = readin_files('assignment.list')\n",
    "#read in all the assignments\n",
    "\n",
    "#######################\n",
    "#Define the fasta file#\n",
    "#######################\n",
    "target = 'target.fasta'\n",
    "\n",
    "for line in open(target, 'r').readlines():\n",
    "    if line[0] == \">\":\n",
    "        target_name = line[1:-1]\n",
    "    else:\n",
    "        target_fasta = line[:-1]\n",
    "print(target_name)\n",
    "print(target_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e81e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting assignment for', target_name)\n",
    "for assign in assignment:\n",
    "    assign = assign.split('\\t')\n",
    "    if target_name == assign[0]:\n",
    "        bw_assign = \"> \" + assign[2]\n",
    "    if target_name == assign[2]:\n",
    "        bw_assign = \"> \" + assign[2]\n",
    "print(target_name, \" was assign as \", bw_assign)\n",
    "#Here the script tries to find the model in the assignment list, so to define bw_assign for the later BW file\n",
    "\n",
    "gpcrdb = open('all_gpcrdb_num.data', 'r')\n",
    "gpcrdb_lines = gpcrdb.readlines()\n",
    "for i in range (0, len(gpcrdb_lines)):\n",
    "    if gpcrdb_lines[i][:-1] == bw_assign:\n",
    "        position = i\n",
    "print(bw_assign, ' can be found in line ',position)\n",
    "#The script gets the information, where in the BW list to find the needed residues\n",
    "\n",
    "fasta_bw = ''\n",
    "fasta = gpcrdb_lines[position + 1]\n",
    "fasta = fasta.split('\\t')\n",
    "fasta[-1] = fasta[-1][:-1]\n",
    "bw = gpcrdb_lines[position + 2]\n",
    "bw = bw.split('\\t')\n",
    "bw[-1] = bw[-1][:-1]\n",
    "for ele in fasta:\n",
    "    fasta_bw = fasta_bw + ele[0]\n",
    "#From the BW all data list the sequence for BW numbering is taken, defined and a list with the names provided\n",
    "\n",
    "alignments = pairwise2.align.globalxx(target_fasta, fasta_bw)\n",
    "#use of Biophython lib and the module pairwise 2\n",
    "aligned_bw = alignments[0][1]\n",
    "aligned_pdb = alignments[0][0]\n",
    "#the alignment will put '-' in spaces were there are differences\n",
    "\n",
    "offset_bw = 0\n",
    "offset_pdb = 0\n",
    "if aligned_pdb[0] == '-':\n",
    "    for residue in aligned_pdb:\n",
    "        if residue != '-':\n",
    "            break\n",
    "        else:\n",
    "            offset_pdb += 1\n",
    "else:\n",
    "    for residue in aligned_bw:\n",
    "        if residue != '-':\n",
    "            break\n",
    "        else:\n",
    "            offset_bw += 1\n",
    "#need to define an offset value (bw sequence starts earlier or later)\n",
    "\n",
    "bw_for_alignment = []           \n",
    "#print(offset_bw, offset_pdb)\n",
    "\n",
    "\n",
    "offset_aligned_in_fasta = 0\n",
    "offset_bw_in_fasta = 0\n",
    "\n",
    "f = open(f\"{bw_assign[2:]}.bw\", 'w')\n",
    "\n",
    "bw_numbering_final = []\n",
    "if offset_bw > offset_pdb: \n",
    "    for i in range(offset_bw, len(target_fasta)):\n",
    "        if aligned_bw[i] == '-':\n",
    "            offset_aligned_in_fasta += 1 \n",
    "        else:\n",
    "            try:\n",
    "                if aligned_pdb[i] == '-':\n",
    "                    offset_bw_in_fasta += 1 \n",
    "                else:\n",
    "                    print(aligned_pdb[i], i + 1 - offset_bw_in_fasta, bw[i - offset_bw - offset_aligned_in_fasta], file=f)\n",
    "                    bw_numbering_final.append((aligned_pdb[i], i + 1 - offset_bw_in_fasta, bw[i - offset_bw - offset_aligned_in_fasta]))\n",
    "            except:\n",
    "                pass\n",
    "#Here happens the magic and it is complicated\n",
    "#We need two further offset values, one k for the bw numbering and z for when in the crystal structure we have\n",
    "#another residue (complicated, but the assignment will make from ex. VASQAS BW and VASNAS Crystal -> VAS-QAS and VASN-AS)\n",
    "#The code will correct this with z (DON'T ASK ME, IT'S MAGIC)\n",
    "\n",
    "else:\n",
    "    for i in range(offset_pdb, len(target_fasta)):\n",
    "        if aligned_bw[i] == '-':\n",
    "            k  += 1 \n",
    "        else:\n",
    "            try:                    \n",
    "                if aligned_pdb[i] == '-':\n",
    "                    z += 1 \n",
    "                else:\n",
    "                    print(aligned_pdb[i], (i + 1 - offset_pdb - offset_bw_in_fasta), bw[i - offset_aligned_in_fasta], file=f)\n",
    "                    bw_numbering_final.append((aligned_pdb[i], (i + 1 - offset_pdb - offset_bw_in_fasta), bw[i - offset_aligned_in_fasta]))\n",
    "            except:\n",
    "                pass\n",
    "#prints AA, number in Rosetta and BW Numbering\n",
    "f.close()       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59669bec",
   "metadata": {},
   "source": [
    "#STEP 2 Make_cst_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37718271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_para():\n",
    "    global weight, distance, harmonic, constant\n",
    "    weight = random.randint(2,4)\n",
    "    distance = (1+float(random.randint(3,7)/100))\n",
    "    harmonic = (random.randint(4,8)/10)\n",
    "    constant = str(-(random.randint(1,10)))\n",
    "random_para()\n",
    "#initialize the random function and generate a first parameter set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c526ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_file = 'ADRB1.bw'\n",
    "distance_pair = []\n",
    "for line in open('selected_pairs.list', 'r').readlines():\n",
    "    line = line.split()\n",
    "    distance_pair.append(line)\n",
    "for pair in distance_pair:\n",
    "    print(pair)\n",
    "#opens the selected distances with res low, res high and distance in A\n",
    "\n",
    "number_of_constraint_files = 10\n",
    "#########################################\n",
    "#    Define the number of constraints   #\n",
    "#This is similar to the number of models#\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, (number_of_constraint_files+1)):\n",
    "    cst_file_name = bw_file[:-3] + '_' + str(i) + '.cst'\n",
    "    cst_file = open(cst_file_name, 'w')\n",
    "    #build a new cst file \n",
    "    constraint = []\n",
    "    tetrahedron_counter = 0\n",
    "    for pair in distance_pair:\n",
    "        tetrahedron_counter += 1\n",
    "        file = open(bw_file, 'r')\n",
    "        res_num = []\n",
    "        for line in file:\n",
    "            line = line.split()\n",
    "            if pair[0] == line[2]:\n",
    "                res_num.append(line[1])\n",
    "            if pair[2] == line[2]:\n",
    "                res_num.append(line[1])\n",
    "        #get the information for the bw pair and corresponding number in the fasta --> final Rosetta res number\n",
    "        try:\n",
    "            print('AtomPair \\t CA \\t', res_num[0], '\\t CA \\t ', res_num[1], '\\t SCALARWEIGHTEDFUNC \\t', \n",
    "            weight, '\\t SUMFUNC \\t 2 \\t HARMONIC \\t', str(round(float(pair[3])*distance, 4)), \n",
    "            '\\t', harmonic, '\\t CONSTANTFUNC \\t', constant, file=cst_file)\n",
    "\n",
    "        except:\n",
    "            print('#There was an error with', res_num[0], res_num[1])\n",
    "            print('#There was an error with', res_num[0], res_num[1])\n",
    "        #write the constraint line into a file, if there is an error --> missing bw number, catch the except \n",
    "        if tetrahedron_counter == 6:\n",
    "            print('#The selected parameters were:', weight, distance, harmonic, constant, file=cst_file)\n",
    "            tetrahedron_counter = 0 \n",
    "            random_para()\n",
    "        #after one tetrahedron (6 pairs of residues), write the selected parameter and generate new ones\n",
    "    cst_file.close()\n",
    "    \n",
    "#simple script, opens new file, starts for each distance pair a new for loop --> opens bw file, searchs for fitting number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc22c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bonus: Write a bash script to copy the constraints and rename XML script\n",
    "bash_script = open('copy_cst_and_xml.sh', 'w')\n",
    "print('cp *.cst ../Step3_RosettaGPCR/input/', file=bash_script)\n",
    "for i in range(1, (number_of_constraint_files+1)):\n",
    "    cst_file_name = bw_file[:-3] + '_' + str(i) + '.cst'\n",
    "    xml_file_name = 'rosetta_cm' + str(i) + '.xml'\n",
    "    print(f'sed \"s/constraint_number/{cst_file_name}/g\" ../Step3_RosettaGPCR/input/rosetta_cm.xml >>../Step3_RosettaGPCR/input/{xml_file_name}',\n",
    "         file=bash_script)\n",
    "bash_script.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8789a2",
   "metadata": {},
   "source": [
    "#STEP 4 Calculate_volume_and_filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f22cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits import mplot3d\n",
    "from scipy.spatial import *\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.system('ls *.pdb > pdb.list')\n",
    "#generate a list with all pdbs\n",
    "\n",
    "def readin_files(file):\n",
    "    data_list = []\n",
    "    with open(file) as open_file:\n",
    "        for line in open_file:\n",
    "            data_list.append(line[:-1])\n",
    "    return data_list\n",
    "#defines the reading of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbcf65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = readin_files('pdb.list')\n",
    "volume_residues = readin_files('selected_res_vol.list')\n",
    "bw_numbering = readin_files('ADRB1.bw')\n",
    "#read in all the necessary files and assignments\n",
    "\n",
    "relevant_vol_res = []\n",
    "for residue in bw_numbering:\n",
    "    res = residue.split()\n",
    "    if res[2] in volume_residues:\n",
    "        relevant_vol_res.append(res[1])\n",
    "print(relevant_vol_res)\n",
    "#build a Rosetta number list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dcf804",
   "metadata": {},
   "outputs": [],
   "source": [
    "for structure in model:\n",
    "    xyz_name = f\"{structure}.xyz\"\n",
    "    xyz_file = open(xyz_name, 'w')\n",
    "    for lines in open(structure, 'r').readlines():\n",
    "        line = lines.split()\n",
    "        try:\n",
    "            if line[5] in relevant_vol_res and line[4] == 'A' and line[2] == 'CA': \n",
    "                print(*line[3:9], sep='\\t', file=xyz_file)\n",
    "        except:\n",
    "            pass\n",
    "    xyz_file.close()\n",
    "#selects from all pdbs the relevant residues (CA atom) and the x, y and z coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd61dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = []\n",
    "for structure in model:\n",
    "    xyz.append((structure + \".xyz\"))\n",
    "\n",
    "counter = 0\n",
    "for ele in xyz:\n",
    "    vol_file = open(f\"{ele}.vol\", \"w\")\n",
    "    points = []\n",
    "    file = open(ele, 'r')\n",
    "    try:\n",
    "        for line in file:\n",
    "            line = line.split()\n",
    "            if \"NA\" not in line:\n",
    "                point = line[-3:]\n",
    "            points.append(point)\n",
    "        hull = ConvexHull(points)\n",
    "\n",
    "        print(ele, hull.volume, file=vol_file)\n",
    "        vol_file.close()\n",
    "        counter += 1\n",
    "        print(counter)\n",
    "    except:\n",
    "        print(ele, \"NA\", file=f)\n",
    "#For calculating the volume of the 10 res and saving them in a new file\n",
    "os.system('find . -name \"*vol\" -exec cat {} > all_vol.list \\;')\n",
    "#One final file for all volumes\n",
    "os.system('find . -name \"*.pdb\" | xargs grep -E \"pose\" > score.list \\;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volume = pd.read_csv('all_vol.list', names=['description', 'volume'], sep='\\s+')\n",
    "df_volume['description'] = df_volume['description'].map(lambda x: str(x)[:-4])\n",
    "df_score = pd.read_csv('score.list', header=None, sep='\\s+')\n",
    "df_score['description'] = df_score[0].map(lambda x: str(x)[2:-5])\n",
    "df_score_final = df_score[[23, 'description']]\n",
    "merged = pd.merge(left=df_volume, right=df_score_final, on='description')\n",
    "merged = merged.rename(columns={23: 'score'})\n",
    "merged\n",
    "#read in the volume and the score files and generates a merged dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76037a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['volume'] = merged['volume'].astype(float)\n",
    "merged['score'] = merged['score'].astype(float)\n",
    "mean_vol = merged['volume'].mean()\n",
    "\n",
    "print(mean_vol)\n",
    "selected = merged.loc[(merged['volume'] > (mean_vol-200)) & (merged['volume'] < (mean_vol+200))]\n",
    "selected.sort_values(by=['score'], inplace=True, ascending=True)\n",
    "selected.to_csv('within_200.list', sep='\\t', index=None)\n",
    "os.system(f'echo \"\\nThe mean_volume was {round(mean_vol, 2)}\" >> within_200.list')\n",
    "best5 = selected.head(5)\n",
    "best5.to_csv('best5.list', sep='\\t', index=None)\n",
    "os.system(f'echo \"\\nThe mean_volume was {round(mean_vol, 2)}\" >> best5.list')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
